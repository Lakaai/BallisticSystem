## Resources

### Stochastic Differential Equations

MIT Lecture Series: https://www.youtube.com/watch?v=qdbkvD4N-us&t=21s&ab_channel=MITOpenCourseWare
Rungeâ€“Kutta Methods for the Strong Approximation of Solutions of Stochastic Differential Equations
Numerical Solution of Stochastic Differential Equations

Seems by far the best:

Applied Stochastic Differential Equations
Book by Arno Solin and Simo SÃ¤rkkÃ¤

 Discrete-time integration of continuous-time stochastic differential equations (SDEs) with sampled noise increments, i.e., stochastic Runge-Kutta integration.

 https://www.cs.unc.edu/~welch/kalman/media/pdf/maybeck_ch1.pdf

 https://z-library.sk/book/2329291/72ed72/introduction-to-stochastic-differential-equations.html


### Gaussian Processes 

ML Tutorial Gaussian Process: https://www.youtube.com/watch?v=92-98SYOdlY&ab_channel=MarcDeisenroth
Visual Exploration of Gaussian Processes: https://distill.pub/2019/visual-exploration-gaussian-processes/

# GLMakie Rendering Issue Fix

Unsure which one of these fixed the rednering issue of fading lines but it was one of them. 

See here for example code: 

https://docs.makie.org/dev/explanations/cameras
 
# Set the NVIDIA adapter as default
export MESA_D3D12_DEFAULT_ADAPTER_NAME=NVIDIA

# Force the D3D12 driver
export GALLIUM_DRIVER=d3d12

# Disable software fallback
export LIBGL_ALWAYS_SOFTWARE=0

# ALL gausssian filtering on slide 48 at time 1:08:56 in video below 
https://www.youtube.com/watch?v=JUDqgLMqrgk&list=PLYzdsV9oalhtLVRx7Se1w-TvIxKInK97g&index=9&ab_channel=LukeThompson


old 
Unscented trasnform code: 

    # else   
    #     Î£ğ‘¥ = density.covariance
    #     Sğ‘¥ = cholesky((L + Î») * Î£ğ‘¥).L  
    #     # Weights Wáµ¢ ğ’˜ ğ‘¾
        
    #     # Plus one because non-zero based indexing
    #     ğ›˜ = zeros(L, 2L + 1)
    #     ğ›˜[:, 1] = Î¼ğ‘¥

    #     for i in 1:L
    #         ğ›˜[:, i+1] = Î¼ğ‘¥ + Sğ‘¥[:, i]
    #         ğ›˜[:, i+1+L] = Î¼ğ‘¥ - Sğ‘¥[:, i]
    #     end

    #     # Construct the weights matrix
    #     ğ‘¾áµ = zeros(2L + 1)
    #     ğ‘¾áµ[1] = Î» / (L + Î»)
    #     ğ‘¾áµ[2:end] .= 1 / (2 * (L + Î»))
        
    #     ğ‘¾á¶œ = zeros(2L + 1)
    #     ğ‘¾á¶œ[1] = Î» / (L + Î») + (1 - Î±^2 + Î²)
    #     ğ‘¾á¶œ[2:end] .= 1 / (2 * (L + Î»))

    #     @assert abs(sum(ğ‘¾áµ) - 1.0) < 1e-12 "Mean weights don't sum to 1"
        
    #     # for i in 1:(2L + 1)
    #     #     @show ğ›˜[:, i]
    #     #     ğ’´[i] = func(ğ›˜[:, i])
    #     # end 

    #     # for i in 1:(2 * L + 1)
    #     #     push!(ğ’´, predict_measurement(ğ›˜[i])) # TODO: Compare the two methods of building Y
    #     # end

    #     # ğ’´ = hcat[predict_measurement(ğ›˜[:, i]) for i in 1:(2L + 1)]
    #     # Î¼ğ‘¦ = sum(ğ‘¾áµ[i] * ğ’´[:, i] for i in 1:(2L + 1))

    #     # Î£ğ‘¦ = sum(ğ‘¾á¶œ[i] * (ğ’´[:, i] - Î¼ğ‘¦) * (ğ’´[:, i] - Î¼ğ‘¦)' for i in 1:(2L + 1)) 

    #     # # Then compute mean as:
    #     # Î¼ğ‘¦ = sum(ğ‘¾áµ[i] * ğ’´[i] for i in 1:(2L + 1))

    #     # # And covariance as:
    #     # Î£ğ‘¦ = sum(ğ‘¾á¶œ[i] * (ğ’´[i] - Î¼ğ‘¦)^2 for i in 1:(2L + 1))

    #     # CLAUDE CODE
    #     # Propagate sigma points
    #     ğ’´ = zeros(Float64, L, 2L + 1)

    #     for i in 1:(2L + 1)
    #         ğ’´[:, i] = func(ğ›˜[:, i])
    #     end
        
    #     # Compute predicted mean and covariance (no Q added here)
    #     Î¼ğ‘¦ = sum(ğ‘¾áµ[i] * ğ’´[:, i] for i in 1:(2L + 1))
    #     Î£ğ‘¦ = sum(ğ‘¾á¶œ[i] * (ğ’´[:, i] - Î¼ğ‘¦) * (ğ’´[:, i] - Î¼ğ‘¦)' for i in 1:(2L + 1))
        
    #     # Ensure symmetry
    #     Î£ğ‘¦ = 0.5 * (Î£ğ‘¦ + Î£ğ‘¦') # TODO: Review thoery 


 AND MORE 


        # # Î¼ğ‘¦ = transformed_density.mean
        # # Î£ğ‘¦ = transformed_density.covariance
        # Î¼ğ‘¥ = density.mean
        # Î£ğ‘¥ = density.covariance
        # L = length(Î¼ğ‘¥)
        
        # # UKF parameters
        # Îº = 0
        # Î± = 0.2
        # Î² = 2
        # Î» = Î±^2 * (L + Îº) - L
        
        # # Add regularization for numerical stability
        # Îµ = 1e-9
        # Î£ğ‘¥_reg = Î£ğ‘¥ + Îµ * I
        
        # # Generate sigma points from STATE distribution
        # Sâ‚“ = cholesky((L + Î») * Î£ğ‘¥_reg).L
        # ğ›˜ = zeros(Float64, L, 2L + 1)
        # ğ›˜[:, 1] = Î¼ğ‘¥
        
        # for i in 1:L
        #     ğ›˜[:, i+1] = Î¼ğ‘¥ + Sâ‚“[:, i]
        #     ğ›˜[:, i+1+L] = Î¼ğ‘¥ - Sâ‚“[:, i]
        # end
        
        # # Weights
        # ğ‘¾áµ = zeros(2L + 1)
        # ğ‘¾á¶œ = zeros(2L + 1)
        # ğ‘¾áµ[1] = Î» / (L + Î»)
        # ğ‘¾á¶œ[1] = Î» / (L + Î») + (1 - Î±^2 + Î²)
        # ğ‘¾áµ[2:end] .= 1 / (2 * (L + Î»))
        # ğ‘¾á¶œ[2:end] .= 1 / (2 * (L + Î»))

        # # Transform sigma points through measurement model
        # ğ’´ = zeros(2L + 1)  # Assuming scalar measurements

        # for i in 1:(2L + 1)
        #     ğ’´[i] = predict_measurement(ğ›˜[:, i])
        # end
        
        # # Compute measurement statistics
        # Î¼ğ‘¦ = sum(ğ‘¾áµ[i] * ğ’´[i] for i in 1:(2L + 1))
        # Î£ğ‘¦ = sum(ğ‘¾á¶œ[i] * (ğ’´[i] - Î¼ğ‘¦)^2 for i in 1:(2L + 1)) + R
        
        # # Compute cross-covariance (state-measurement)
        # Î£ğ‘¥ğ‘¦ = sum(ğ‘¾á¶œ[i] * (ğ›˜[:, i] - Î¼ğ‘¥) * (ğ’´[i] - Î¼ğ‘¦) for i in 1:(2L + 1))
        
        # # Kalman update
        # K = Î£ğ‘¥ğ‘¦ / Î£ğ‘¦
        # innovation = measurement - Î¼ğ‘¦
        # Î¼_updated = Î¼ğ‘¥ + K * innovation
        # Î£_updated = Î£ğ‘¥ - K * Î£ğ‘¥ğ‘¦'  # More numerically stable than K * Î£ğ‘¦ * K'
        
        # # Ensure symmetry
        # Î£_updated = 0.5 * (Î£_updated + Î£_updated')